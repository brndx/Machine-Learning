{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "itr = train_generator = train_datagen.flow_from_directory(\n",
    "        'data/training',\n",
    "        target_size=(28, 28),\n",
    "        batch_size=60000,\n",
    "        class_mode='binary')\n",
    "\n",
    "test = test_generator = test_datagen.flow_from_directory(\n",
    "        'data/testing',\n",
    "        target_size=(28,28),\n",
    "        batch_size=10000,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = itr.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, validationX, trainY, validationY = train_test_split(X,\n",
    "                                Y, train_size=0.9, test_size=0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000,)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 28, 28, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = test.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as grayscale\n",
    "plt.subplot(221)\n",
    "plt.imshow(trainX[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(trainX[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(trainX[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(trainX[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(350, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_20_input to have 2 dimensions, but got array with shape (60000, 28, 28, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-132-1f364f39d1f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit_generator(generator=train_generator,\n\u001b[0;32m      2\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1207\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m             class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_20_input to have 2 dimensions, but got array with shape (60000, 28, 28, 3)"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=test_generator,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_20_input to have 2 dimensions, but got array with shape (54000, 28, 28, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-7f1dc8ae7514>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(trainX, trainY,\n\u001b[1;32m----> 2\u001b[1;33m validation_data=(validationX,validationY), epochs=5)\n\u001b[0m",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    951\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\envs\\deep-learning-keras\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    125\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    128\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_20_input to have 2 dimensions, but got array with shape (54000, 28, 28, 3)"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY,\n",
    "validation_data=(validationX,validationY), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-61969f6517af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# if data are in form of images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "'''    import os \n",
    "    import numpy as np \n",
    "    from keras.preprocessing import image\n",
    "     \n",
    "    PATH = os.getcwd()\n",
    "     \n",
    "    train_path = PATH+'\\\\data\\\\training'\n",
    "    train_batch = os.listdir(train_path)\n",
    "    x_train = []\n",
    "     \n",
    "    # if data are in form of images\n",
    "    for sample in train_data:\n",
    "        img_path = train_path+sample\n",
    "        x = image.load_img(img_path)\n",
    "        # preprocessing if required\n",
    "        x_train.append(x)\n",
    "     \n",
    "    test_path = PATH+'\\\\data\\\\testing'\n",
    "    test_batch = os.listdir(test_path)\n",
    "    x_test = []\n",
    "     \n",
    "    for sample in test_data:\n",
    "        img_path = test_path+sample\n",
    "        x = image.load_img(img_path)\n",
    "        # preprocessing if required\n",
    "        x_test.append(x)\n",
    "    \n",
    "    # finally converting list into numpy array\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
