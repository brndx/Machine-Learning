{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, Flatten\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "itr = train_generator = train_datagen.flow_from_directory(\n",
    "        'data/training',\n",
    "        target_size=(28, 28),\n",
    "        batch_size=60000,\n",
    "        class_mode='binary')\n",
    "\n",
    "test = test_generator = test_datagen.flow_from_directory(\n",
    "        'data/testing',\n",
    "        target_size=(28,28),\n",
    "        batch_size=10000,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = itr.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 3)"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2352)"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX, validationX, trainY, validationY = train_test_split(X,\n",
    "                                Y, train_size=0.9, test_size=0.1, random_state = 0)\n",
    "testX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54000,)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validationY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX, testY = test.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot 4 images as grayscale\n",
    "plt.subplot(221)\n",
    "plt.imshow(trainX[0], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(222)\n",
    "plt.imshow(trainX[1], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(223)\n",
    "plt.imshow(trainX[2], cmap=plt.get_cmap('gray'))\n",
    "plt.subplot(224)\n",
    "plt.imshow(trainX[3], cmap=plt.get_cmap('gray'))\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = trainX/255\n",
    "validationX = validationX/255\n",
    "testX = testX/255\n",
    "\n",
    "trainY = np_utils.to_categorical(trainY)\n",
    "validationY = np_utils.to_categorical(validationY)\n",
    "testY = np_utils.to_categorical(testY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pixels = trainX.shape[1] * trainX.shape[2] * trainX.shape[3]\n",
    "trainX = trainX.reshape(trainX.shape[0],\n",
    "num_pixels).astype('float32')\n",
    "validationX = validationX.reshape(validationX.shape[0],\n",
    "num_pixels).astype('float32')\n",
    "testX = testX.reshape(testX.shape[0], num_pixels).astype('float32')\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(350, input_dim=num_pixels, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 51s 943us/step - loss: 0.9712 - acc: 0.7159 - val_loss: 0.6631 - val_acc: 0.7893\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 35s 647us/step - loss: 0.6097 - acc: 0.8091 - val_loss: 0.5930 - val_acc: 0.8153\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 35s 645us/step - loss: 0.5507 - acc: 0.8268 - val_loss: 0.5425 - val_acc: 0.8288\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 35s 647us/step - loss: 0.5015 - acc: 0.8424 - val_loss: 0.4982 - val_acc: 0.8412\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 35s 648us/step - loss: 0.4536 - acc: 0.8591 - val_loss: 0.4524 - val_acc: 0.8602\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainX, trainY,\n",
    "validation_data=(validationX,validationY), epochs=5)\n",
    "training_accuracy = history.history['acc']\n",
    "validation_accuracy = history.history['val_acc']\n",
    "training_error = history.history['loss']\n",
    "validation_error = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Error on test set: 11.06%\n",
      "MLP Accuracy on test set: 88.94%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(testX, testY, verbose=0)\n",
    "print(\"MLP Error on test set: %.2f%%\" % (100-scores[1]*100))\n",
    "print(\"MLP Accuracy on test set: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"    import os \\n    import numpy as np \\n    from keras.preprocessing import image\\n     \\n    PATH = os.getcwd()\\n     \\n    train_path = PATH+'\\\\data\\\\training'\\n    train_batch = os.listdir(train_path)\\n    x_train = []\\n     \\n    # if data are in form of images\\n    for sample in train_data:\\n        img_path = train_path+sample\\n        x = image.load_img(img_path)\\n        # preprocessing if required\\n        x_train.append(x)\\n     \\n    test_path = PATH+'\\\\data\\\\testing'\\n    test_batch = os.listdir(test_path)\\n    x_test = []\\n     \\n    for sample in test_data:\\n        img_path = test_path+sample\\n        x = image.load_img(img_path)\\n        # preprocessing if required\\n        x_test.append(x)\\n    \\n    # finally converting list into numpy array\\n    x_train = np.array(x_train)\\n    x_test = np.array(x_test)\""
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    import os \n",
    "    import numpy as np \n",
    "    from keras.preprocessing import image\n",
    "     \n",
    "    PATH = os.getcwd()\n",
    "     \n",
    "    train_path = PATH+'\\\\data\\\\training'\n",
    "    train_batch = os.listdir(train_path)\n",
    "    x_train = []\n",
    "     \n",
    "    # if data are in form of images\n",
    "    for sample in train_data:\n",
    "        img_path = train_path+sample\n",
    "        x = image.load_img(img_path)\n",
    "        # preprocessing if required\n",
    "        x_train.append(x)\n",
    "     \n",
    "    test_path = PATH+'\\\\data\\\\testing'\n",
    "    test_batch = os.listdir(test_path)\n",
    "    x_test = []\n",
    "     \n",
    "    for sample in test_data:\n",
    "        img_path = test_path+sample\n",
    "        x = image.load_img(img_path)\n",
    "        # preprocessing if required\n",
    "        x_test.append(x)\n",
    "    \n",
    "    # finally converting list into numpy array\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
