{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- IMPORT LIBRARIES ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- FUNCTIONS ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataTarget):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(dataTarget)\n",
    "    class_labels = le.transform(dataTarget)\n",
    "    \n",
    "    return class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessData(data):\n",
    "    data = data.replace('Unknown', np.nan)\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDt(dataAttrs, dataTarget):\n",
    "    #construct decision tree\n",
    "    clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    clf = clf.fit(dataAttrs, dataTarget)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPred(df, testX, testY):\n",
    "    predictions = df.predict(testX)\n",
    "    print(metrics.classification_report(testY, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGraph(clf, X, Y):\n",
    "    dot_data = tree.export_graphviz(clf, out_file = None,\n",
    "                                feature_names =X.columns,\n",
    "                                class_names= Y,\n",
    "                                filled = True,\n",
    "                                rounded= False,\n",
    "                                special_characters = True\n",
    "                               )\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, testX):\n",
    "    prediction = df.predict(testX)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAccuracy(clf, testX, testY):\n",
    "    prediction = predict(clf, testX)\n",
    "    accuracy = accuracy_score(testY, prediction)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(clf, testX, testY):\n",
    "    prediction = predict(clf, testX)\n",
    "    accuracy = accuracy_score(testY, prediction)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- TRYING OUT SCRIPTS ----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRIPT FOR BACKWARD SUBSET FEATURE SELECTION - ONE AT THE TIME \n",
    "attribute = ['address', 'rooms', 'type', 'method', 'realestate_agent', 'date', 'distance', 'postcode', 'bedrooms',\n",
    "             'bathrooms', 'car_parks', 'landsize', 'building_area', 'year_built',\n",
    "            'council_area', 'lattitude', 'longtitude', 'region_name', 'suburb_property_count']\n",
    "\n",
    "acc_score = []\n",
    "\n",
    "propertyData = pd.read_csv(\"property_prices.csv\")\n",
    "\n",
    "propertyData = preprocessData(propertyData)\n",
    "\n",
    "propertyData['lowBand'], propertyData['highBand'] = propertyData['price_bands'].str.split('-', 1).str\n",
    "propertyData['lowBand'] = propertyData['lowBand'].str[:-1]\n",
    "propertyData['highBand'] = propertyData['highBand'].str[:-1]\n",
    "\n",
    "for attr in attribute: \n",
    "\n",
    "    Y = propertyData['lowBand']\n",
    "    X = propertyData.drop(columns=['id','lowBand', 'highBand','price_bands', attr])\n",
    "\n",
    "    XE = pd.get_dummies(X)\n",
    "    trainX, testX, trainY, testY = train_test_split(np.array(XE), np.array(Y), test_size=0.2)\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(trainY)\n",
    "    class_labels = le.inverse_transform([0,1,2,3,4,5,6])\n",
    "\n",
    "    clf = buildDt(trainX, trainY)\n",
    "    accuracy = getAccuracy(clf, testX, testY)\n",
    "    acc_score.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINTING THE ACCURACY SCORE FOR EACH ATTRIBUTE, IF HIGH = REMOVE \n",
    "attribute = ['address', 'rooms', 'type', 'method', 'realestate_agent', 'date', 'distance', 'postcode', 'bedrooms',\n",
    "             'bathrooms', 'car_parks', 'landsize', 'building_area', 'year_built',\n",
    "            'council_area', 'lattitude', 'longtitude', 'region_name', 'suburb_property_count']\n",
    "\n",
    "attr = []\n",
    "for a in attribute:\n",
    "    attr.append(a[:3])\n",
    "    \n",
    "fig = plt.figure()\n",
    "fig = plt.plot(attr, acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCRIPT FOR SEVERAL ITERATIONS OF BACKWARD SUBSET FEATURE SELECTION\n",
    "import copy\n",
    "attribute = ['address', 'rooms', 'type', 'method', 'realestate_agent', 'date', 'distance', 'postcode', 'bedrooms',\n",
    "             'bathrooms', 'car_parks', 'landsize', 'building_area', 'year_built',\n",
    "            'council_area', 'lattitude', 'longtitude', 'region_name', 'suburb_property_count']\n",
    "\n",
    "droppedColumns = ['id','lowBand', 'highBand','price_bands']\n",
    "\n",
    "previous_accuracy = 0\n",
    "\n",
    "propertyData = pd.read_csv(\"property_prices.csv\")\n",
    "\n",
    "propertyData = preprocessData(propertyData)\n",
    "\n",
    "propertyData['lowBand'], propertyData['highBand'] = propertyData['price_bands'].str.split('-', 1).str\n",
    "propertyData['lowBand'] = propertyData['lowBand'].str[:-1]\n",
    "propertyData['highBand'] = propertyData['highBand'].str[:-1]\n",
    "\n",
    "Y = propertyData['lowBand']\n",
    "        \n",
    "while True:\n",
    "    acc_score = []\n",
    "    \n",
    "    for attr in attribute: \n",
    "\n",
    "        dropCopy = copy.copy(droppedColumns)\n",
    "        dropCopy.extend([attr])\n",
    "        \n",
    "        X = propertyData.drop(columns=dropCopy)\n",
    "        \n",
    "        XE = pd.get_dummies(X)\n",
    "        trainX, testX, trainY, testY = train_test_split(np.array(XE), np.array(Y), test_size=0.2)\n",
    "\n",
    "       # le = preprocessing.LabelEncoder()\n",
    "       # le.fit(trainY)\n",
    "       # class_labels = le.inverse_transform([0,1,2,3,4,5,6])\n",
    "\n",
    "        clf = buildDt(trainX, trainY)\n",
    "        accuracy = getAccuracy(clf, testX, testY)\n",
    "        acc_score.append(accuracy)\n",
    "\n",
    "    max_index = 0\n",
    "    for i in range(len(acc_score)):\n",
    "        if(acc_score[i] > acc_score[max_index]):\n",
    "            max_index = i\n",
    "\n",
    "    droppedColumns.append(attribute[max_index])\n",
    "    attribute.pop(max_index)\n",
    "    current_accuracy = acc_score[max_index]\n",
    "    \n",
    "    if(current_accuracy < previous_accuracy):\n",
    "        break\n",
    "    else:\n",
    "        previous_accuracy = current_accuracy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the attributes we are left with \n",
    "attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the attributes that were dropped\n",
    "droppedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the accuracy before the script stopped\n",
    "previous_accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
